<h1 id="neural2d---neural-net-simulator">Neural2d - Neural Net Simulator</h1>
<h1 id="user-manual">User Manual</h1>
<p>Ver. 1.0</p>
<h2 id="features">Features</h2>
<ul>
<li>Optimized for 2D image data -- input data can be read from .bmp image files</li>
<li>Neuron layers can be abstracted as 1D or 2D arrangements of neurons</li>
<li>Network topology is defined in a text file</li>
<li>Neurons in layers can be fully or sparsely connected</li>
<li>Selectable transfer function per layer</li>
<li>Adjustable or automatic training rate (eta)</li>
<li>Optional momentum (alpha) and regularization (lambda)</li>
<li>Any layer(s) can be configured as convolution filters</li>
<li>Standalone console program</li>
<li>Simple, heavily-commented code, &lt; 3000 lines, suitable for prototyping, learning, and experimentation</li>
<li>Optional web-browser-based GUI controller</li>
</ul>
<h2 id="document-contents">Document Contents</h2>
<p><a href="#Requirements">Requirements</a><br /><a href="#Demo">How to run the digits demo</a><br /><a href="#XorExample">How to run the XOR example</a><br /><a href="#GUI">GUI interface</a><br /><a href="#YourOwnData">How to use your own data</a><br /><a href="#2D">The 2D in neural2d</a><br /><a href="#Convolution">Convolution filtering</a><br /><a href="#TopologyConfig">Topology config file format</a><br /><a href="#TopologyExamples">Topology config file examples</a><br /><a href="#HowDoI">How-do-I <em>X</em>?</a><br />* <a href="#howInstall">How do I get, build, and install the command-line neural2d program?</a><br />* <a href="#howConsole">How do I run the command-line program?</a><br />* <a href="#howGui">How do I run the GUI interface?</a><br />* <a href="#howOwnData">How do I use my own data instead of the digits images?</a><br />* <a href="#howTrained">How do I use a trained net on new data?</a><br />* <a href="#MNIST">How do I train on the MNIST handlwritten digits data set?</a><br />* <a href="#howEta">How do I change the learning rate parameter?</a><br />* <a href="#howBinary">Are the output neurons binary or floating point?</a><br />* <a href="#howTf">How do I use a different transfer function?</a><br />* <a href="#howConvolve">How do I define a convolution filter?</a><br />* <a href="#howRgb">How do the color image pixels get converted to floating point for the input layer?</a><br />* <a href="#howJpg">How can I use .jpg and .png images as inputs to the net?</a><br />* <a href="#howLearn">Why does the net error rate stay high? Why doesn't my net learn?</a><br />* <a href="#howParams">What other parameters do I need to know about?</a></p>
<p><a href="#Licenses">Licenses</a></p>
<p>Also see the <a href="https://github.com/davidrmiller/neural2d/wiki">wiki</a> for more information.</p>
<h2 id="requirements">Requirements<a name="Requirements"></a></h2>
<ul>
<li>C++-11 compiler (e.g., g++ on Linux)</li>
<li>POSIX sockets (e.g., Cygwin on Windows)</li>
<li>Compiles and runs on Linux, Windows, and probably Mac</li>
</ul>
<h2 id="how-to-run-the-digits-demo">How to run the digits demo<a name="Demo"></a></h2>
<p>Place all the files, maintaining the relative directory structure, into a convenient directory.</p>
<p>In the images/digits/ subdirectory, extract the image files from the archive into the same directory.</p>
<p>To compile neural2d, cd to the directory containing the Makefile and execute the default make target:</p>
<pre><code>make</code></pre>
<p>This will use g++ to compile neural2d.cpp and neural2d-core.cpp and result in an executable named neural2d.</p>
<p>To run the demo, execute:</p>
<pre><code>make test</code></pre>
<p>In this demo, we train the neural net to recognize digits. The input data, or &quot;training set&quot;, consists of a few thousand images of numeric digits. The first 50 look like these:</p>
<div class="figure">
<img src="https://raw.github.com/davidrmiller/neural2d/master/images/digits-illus.png" alt="training samples" /><p class="caption">training samples</p>
</div>
<p>The images are 32x32 pixels each, stored in .bmp format. In this demo, the neural net is configured to have 32x32 input neurons, and 10 output neurons. The net is trained to classify the digits in the images and to indicate the answer by driving the corresponding output neuron to a high level.</p>
<p>Once the net is sufficiently trained, all the connection weights are saved in a file named &quot;weights.txt&quot;.</p>
<h2 id="how-to-run-the-xor-example">How to run the XOR example<a name="XorExample"></a></h2>
<p>In the top level directory where the Makefile lives, execute:</p>
<pre><code> make test-xor</code></pre>
<p>For more information about the XOR example, see <a href="https://github.com/davidrmiller/neural2d/wiki/XOR_Example">this wiki page</a>.</p>
<h2 id="gui-interface-optional">GUI interface (optional)<a name="GUI"></a></h2>
<p>First, launch the neural2d console program in a command window with the -p option:</p>
<pre><code> ./neural2d topology.txt inputData.txt weights.txt -p</code></pre>
<p>The -p option causes the neural2d program to wait for a command before starting the training. The screen will look something like this:</p>
<div class="figure">
<img src="https://raw.github.com/davidrmiller/neural2d/master/images/console1.png" alt="console-window" /><p class="caption">console-window</p>
</div>
<p>At this point, the neural2d console program is paused and waiting for a command to continue. Using any web browser, open:</p>
<pre><code> http://localhost:24080</code></pre>
<p>A GUI interface will appear that looks like:</p>
<div class="figure">
<img src="https://raw.github.com/davidrmiller/neural2d/master/images/gui2-sm.png" alt="HTTP interface" /><p class="caption">HTTP interface</p>
</div>
<p>Press Resume to start the neural net training. It will automatically pause when the average error rate falls below a certain threshold (or when you press Pause). You now have a trained net. You can press Save Weights to save the weights for later use.</p>
<h2 id="how-to-use-your-own-data">How to use your own data<a name="YourOwnData"></a></h2>
<p>If you are inputting data from image files, you'll need to prepare a set of BMP image files and an input data config file. The config file (named inputData.txt by default) is a list of image filenames to use as inputs to the neural net, and optionally the target output values for each image. The format looks like this example:</p>
<pre><code>images/thumbnails/test-918.bmp -1 1 -1 -1 -1 -1 -1 -1 -1 -1
images/thumbnails/test-919.bmp -1 -1 -1 -1 -1 -1 -1 -1 1 -1
images/thumbnails/test-920.bmp -1 -1 -1 -1 -1 -1 1 -1 -1 -1
images/thumbnails/test-921.bmp -1 -1 -1 -1 -1 1 -1 -1 -1 -1</code></pre>
<p>The path and filename cannot contain any spaces.</p>
<p>If you are not using image files for input, you'll need to prepare an input config file (named inputData.txt by default) similar to the above but with the literal input values inside curly braces. For example, for a net with eight inputs and two outputs, the format is like this:</p>
<pre><code> { 0.32 0.98 0.12 0.44 0.98 1.2 1 -1 } -1 1 </code></pre>
<p>You'll also need a topology config file (named topology.txt by default). It contains a specification of the neural net topology (the number and arrangement of neurons and connections). Its format is described in a later section. A typical one looks something like this:</p>
<pre><code>input size 32x32  
layer1 size 32x32 from input radius 8x8  
layer2 size 16x16 from layer1  
output size 1x10 from layer2  </code></pre>
<p>Then run neuron2d (optionally with the web browser interface) and experiment with the parameters until the net is adequately trained, then save the weights in a file for later use.</p>
<p>If you run the web interface, you can change the global parameters from the GUI while the neural2d program is running. If you run the neural2d console program without the GUI interface, there is no way to interact with it while running. Instead, you'll need to examine and modify the parameters in the code at the top of the files neural2d.cpp and neural2d-core.cpp.</p>
<h2 id="the-2d-in-neural2d">The 2D in neural2d<a name="2D"></a></h2>
<p>In a simple traditional neural net model, the neurons are arranged in a column in each layer:</p>
<div class="figure">
<img src="https://raw.github.com/davidrmiller/neural2d/master/images/net-542-sm.png" />
</div>
<p>In neural2d, you can specify a rectangular arrangement of neurons in each layer, such as:</p>
<div class="figure">
<img src="https://raw.github.com/davidrmiller/neural2d/master/images/net-5x5-4x4-2-sm.png" />
</div>
<p>The neurons can be sparsely connected to mimic how retinal neurons are connected in biological brains. For example, if a radius of &quot;1x1&quot; is specified in the topology config file, each neuron on the right (destination) layer will connect to a circular patch of neurons in the left (source) layer as shown here (only a single neuron on the right side is shown connected in this picture so you can see what's going on, but imagine all of them connected in the same pattern):</p>
<div class="figure">
<img src="https://raw.github.com/davidrmiller/neural2d/master/images/proj-1x1-sm.png" alt="radius-1x1" /><p class="caption">radius-1x1</p>
</div>
<p>The pattern that is projected onto the source layer is elliptical. (Layers configured as convolution filters work slightly differently; see the later section about convolution filtering.)</p>
<p>Here are some projected connection patterns for various radii:</p>
<p>radius 0x0<br /><img src="https://raw.github.com/davidrmiller/neural2d/master/images/radius-0x0.png" /></p>
<p>radius 1x1<br /><img src="https://raw.github.com/davidrmiller/neural2d/master/images/radius-1x1.png" /></p>
<p>radius 2x2<br /><img src="https://raw.github.com/davidrmiller/neural2d/master/images/radius-2x2.png" /></p>
<p>radius 3x1<br /><img src="https://raw.github.com/davidrmiller/neural2d/master/images/radius-3x1.png" /></p>
<h2 id="convolution-filtering">Convolution filtering<a name="Convolution"></a></h2>
<p>Any layer other than the input layer can be configured as a convolution filter layer by specifying a <em>convolve-matrix</em> specification for the layer in the topology config file. The neurons are still called neurons, but their operation differs in the following ways:</p>
<ul>
<li><p>The connection pattern to the source layer is defined by the convolution matrix (kernel) dimensions (not by a <em>radius</em> parameter)</p></li>
<li><p>The connection weights are initialized from the convolution matrix, and are constant throughout the life of the net.</p></li>
<li><p>The transfer function is automatically set to the identity function (not by a <em>tf</em> parameter).</p></li>
</ul>
<p>For example, the following line in the topology config file defines a 3x3 convolution matrix for shrarpening the source layer:</p>
<pre><code> layerConv1 size 64x64 from input convolve {{0,-1,0},{-1,5,-1},{0,-1,0}}</code></pre>
<p>When a convolution matrix is specified for a layer, you cannot also specify a <em>radius</em> parameter for that layer, as the convolution matrix size determines the size and shape of the rectangle of neurons in the source layer. You also cannot also specify a <em>tf</em> parameter, because the transfer function on a convolution layer is automatically set to be the identity function.</p>
<p>The elements of the convolution matrix are stored as connection weights to the source neurons. Connection weights on convolution layers are not updated by the back propagation algorithm, so they remain constant for the life of the net.</p>
<p>The results are undefined if a layer is defined as both a convolution layer and a regular layer.</p>
<p>For illustrations of various convolution kernels, see <a href="http://en.wikipedia.org/wiki/Kernel_%28image_processing%29">this Wikipedia article</a></p>
<p>In the following illustration, the topology config file defines a convolution filter with a 2x2 kernel that is applied to the input layer, then the results are combined with a reduced-resolution fully-connected pathway. The blue connections in the picture are the convolution connections; the green connections are regular neural connections:</p>
<pre><code>input size 8x8
layerConvolve size 8x8 from input convolve {{-1,2},{-1,2}}
layerReducedRes size 4x4 from input
output size 2 from layerConvolve
output size 2 from layerReducedRes</code></pre>
<div class="figure">
<img src="https://raw.github.com/davidrmiller/neural2d/master/images/net-convolve-8x8.png" />
</div>
<h2 id="topology-config-file-format">Topology config file format<a name="TopologyConfig"></a></h2>
<p>The topology config file contains lines of the following format:</p>
<blockquote>
<p><em>layer-definition-line</em> := <em>layer-name</em> size <em>size-spec</em> [from <em>layer-name</em>] [channel <em>channel-name</em>] [radius <em>size-spec</em>] [tf <em>transfer-function</em>] [convolve <em>convolve-matrix</em>]</p>
</blockquote>
<p>where</p>
<blockquote>
<p><em>layer-name</em> := &quot;input&quot;, &quot;output&quot;, or a string that begins with &quot;layer&quot;</p>
</blockquote>
<blockquote>
<p><em>size-spec</em> := <em>integer</em> [&quot;x&quot; <em>integer</em>]</p>
</blockquote>
<blockquote>
<p><em>channel-name</em> := R, G, B, or BW</p>
</blockquote>
<blockquote>
<p><em>transfer-function</em> := &quot;tanh&quot;, &quot;logistic&quot;, &quot;linear&quot;, &quot;ramp&quot;, or &quot;gaussian&quot;</p>
</blockquote>
<blockquote>
<p><em>convolve-matrix</em> := same {{,},{,}} syntax used for array initialization in C, C#, VB, Java, etc.</p>
</blockquote>
<p>Rules:</p>
<ol style="list-style-type: decimal">
<li><p>Comment lines that begin with &quot;#&quot; and blank lines are ignored.</p></li>
<li><p>The first layer defined must be named &quot;input&quot;.</p></li>
<li><p>The last layer defined must be named &quot;output&quot;.</p></li>
<li><p>The hidden layers can be named anything beginning with &quot;layer&quot;.</p></li>
<li><p>The argument for &quot;from&quot; must be a layer already defined.</p></li>
<li><p>The color channel parameter can be specified only on the input layer.</p></li>
<li><p>A convolution matrix specification cannot appear on the same layer with a <em>radius</em> or <em>tf</em> spec.</p></li>
<li><p>The same layer name can be defined multiple times with different &quot;from&quot; parameters. This allows source neurons from more than one layer to be combined in one destination layer. The source layers can be any size. When a destination layer is defined more than once, each line must have an identical size parameter. In the following example, layerCombined correctly appears twice with the same size specification:</p>
<p>input size 128x128<br /> layerVertical size 32x32 from input radius 1x8<br /> layerHorizontal size 16x16 from input radius 8x1<br /> <strong>layerCombined</strong> size <strong>8x8</strong> from layerVertical<br /> <strong>layerCombined</strong> size <strong>8x8</strong> from layerHorizontal<br /> output size 1 from layerCombined</p></li>
<li><p>The <em>size-spec</em> can specify two dimensions, or one. Spaces are not allowed in the size spec. If only one dimension is given, the other is assumed to be 1. For example:</p></li>
</ol>
<ul>
<li>&quot;8x8&quot; means 64 neurons in an 8 x 8 arrangement.<br /></li>
<li>&quot;8x1&quot; means a row of 8 neurons</li>
<li>&quot;1x8&quot; means a column of 8 neurons.<br /></li>
<li>&quot;8&quot; means the same as &quot;8x1&quot;</li>
</ul>
<h2 id="topology-config-file-examples">Topology config file examples<a name="TopologyExamples"></a></h2>
<p>Here are a few complete topology config files and the nets they specify.</p>
<pre><code>input size 4x4
layer1 size 3x3 from input
layer2 size 2x2 from layer1
output size 1 from layer2</code></pre>
<div class="figure">
<img src="https://raw.github.com/davidrmiller/neural2d/master/images/net-4x4-3x3-2x2-1-sm.png" />
</div>
<pre><code>input size 4x4
layer1 size 1x4 from input
layer2 size 3x1 from layer1
output size 1 from layer2</code></pre>
<div class="figure">
<img src="https://raw.github.com/davidrmiller/neural2d/master/images/net-4x4-1x4-3x1-1-sm.png" />
</div>
<pre><code>input size 4x4
output size 4x1 from input radius 0x2</code></pre>
<div class="figure">
<img src="https://raw.github.com/davidrmiller/neural2d/master/images/net-4x4-4x1r0x2-sm.png" />
</div>
<pre><code>input size 16x16
layer1 size 4x4 from input radius 1x1
output size 7x1 from layer1</code></pre>
<div class="figure">
<img src="https://raw.github.com/davidrmiller/neural2d/master/images/net-16x16-4x4r1x1-7-sm.png" />
</div>
<pre><code># In the picture that follows, layerVertical is the set of 4 neurons
# in the upper part of the picture, and layerHorizontal is the lower
# set of 4 neurons.

input size 6x6
layerHorizontal size 2x2 from input radius 2x0
layerVertical size 2x2 from input radius 0x2
output size 1 from layerHorizontal
output size 1 from layerVertical</code></pre>
<div class="figure">
<img src="https://raw.github.com/davidrmiller/neural2d/master/images/net-6x6-2x2r2x0-2x2r0x2-1-sm.png" />
</div>
<pre><code># This example shows how vertical and horizontal image features can be
# extracted through separate paths and combined in a subsequent layer.

input size 4x4

layerH1 size 1x4 from input radius 4x0
layerH2 size 1x4 from layerH1
layerH3 size 1x4 from layerH2

layerV1 size 4x1 from input radius 0x4
layerV2 size 4x1 from layerV1
layerV3 size 4x1 from layerV2

output size 2 from layerV3
output size 2 from layerH3</code></pre>
<div class="figure">
<img src="https://raw.github.com/davidrmiller/neural2d/master/images/net-4x4-hv-deep-sm.png" />
</div>
<h2 id="how-do-i-x">How-do-I X?<a name="HowDoI"></a></h2>
<p><strong>How do I get, build, and install the command-line neural2d program?</strong><a name="howInstall"></a></p>
<p>Get the files from:</p>
<pre><code>https://github.com/davidrmiller/neural2d</code></pre>
<p>Put those into a directory. Expand the images files in the images/digits/ subdirectory. In the top level directory (where the Makefile lives), build the program with:</p>
<pre><code> make</code></pre>
<p>That will produce an executable named neuron2d in the same directory.</p>
<p>To test the installation, run:</p>
<pre><code> make test</code></pre>
<p>If it succeeds, it will create a weights.txt file of non-zero size.</p>
<p><strong>How do I run the command-line program?</strong><a name="howConsole"></a></p>
<pre><code> ./neural2d topology.txt inputData.txt weights.txt</code></pre>
<p><strong>How do I run the GUI interface?</strong><a name="howGui"></a></p>
<p>First launch the neural2d program with the -p option:</p>
<pre><code> ./neural2d topology.txt inputData.txt weights.txt -p</code></pre>
<p>Then open a web browser and point it at <a href="http://localhost:24080">http://localhost:24080</a> .</p>
<p>If your firewall complains, you may need to allow access to TCP port 24080.</p>
<p><strong>How do I use my own data instead of the digits images?</strong><a name="howOwnData"></a></p>
<p>Create your own directory of BMP images, and a config file that follows the same format as shown in the provided default inputData.txt. Then define a topology config file with the appropriate number of network inputs and outputs, then run the neural2d program.</p>
<p>Or if you don't want to use image files for input, make an input config file containing all the literal input values and the target output values. The format is described in an earlier section.</p>
<p><strong>How do I use a trained net on new data?</strong><a name="howTrained"></a></p>
<p>It's all about the weights file. After the net has been successfully trained, save the internal connection weights in a weights file. That's typically done in neural2d.cpp by calling the member function saveWeights(filename).</p>
<p>The weights you saved can be loaded back into a neural net of the same topology using the member function loadWeights(filename). Once the net has been loaded with weights, it can be used applied to new data by calling feedForward(). Prior to calling feedForward(), you'll want to set a couple of parameters:</p>
<pre><code> myNet.repeatInputSamples = false;
 myNet.reportEveryNth = 1;</code></pre>
<p>This is normally done in neural2d.cpp.</p>
<p>You'll need to prepare a new input data config file (default name inputData.txt) that contains a list of only those new input data images that you want the net to process.</p>
<p><strong>How do I train on the MNIST handlwritten digits data set?</strong><a name="MNIST"></a></p>
<p>See the <a href="https://github.com/davidrmiller/neural2d/wiki/MNIST_Handwritten_dataset">instructions in the wiki</a>.</p>
<p><strong>How do I change the learning rate parameter?</strong><a name="howEta"></a></p>
<p>In the command-line program, you can set the eta parameter or change it by directly setting the eta member of the Net object, like this:</p>
<pre><code> myNet.eta = 0.1;</code></pre>
<p>When using the web interface, you can change the eta parameter (and other parameters) in the GUI at any time, even while the network is busy processing input data.</p>
<p>Also see the <a href="https://github.com/davidrmiller/neural2d/wiki/ParameterList">Parameter List</a> in the wiki.</p>
<p><strong>Are the output neurons binary or floating point?</strong><a name="howBinary"></a></p>
<p>They are interpreted in whatever manner you train them to be, but you can only train the outputs to take values in the range that the transfer function is capable of producing.</p>
<p>If you're training a net to output binary values, it's best if you use the maxima of the transfer function to represent the two binary values. For example, when using the default tanh() transfer function, train the outputs to be -1 and +1 for false and true. When using the logistic transfer function, train the outputs to be 0 and 1.</p>
<p><strong>How do I use a different transfer function?</strong><a name="howTf"></a></p>
<p>You can add a &quot;tf&quot; parameter to any layer definition line in the topology config file. The argument to tf can be &quot;tanh&quot;, &quot;logistic&quot;, &quot;linear&quot;, &quot;ramp&quot;, or &quot;gaussian&quot;. The transfer function you specify will be used by all the neurons in that layer. See neural2d-core.cpp for more information.</p>
<p>In the topology config file, the tf parameter is specified as in this example:</p>
<pre><code> layerHidden1 size 64x64 from input radius 3x3 tf linear</code></pre>
<p>You can add new transfer functions by following the examples in neural2d-core.cpp. There are two places to change: first find where transferFunctionTanh() is defined and add your new transfer function and its derivative there. Next, locate the constructor for class Neuron and add a new else-if clause there, following the examples.</p>
<p><strong>How do I define a convolution filter?</strong><a name="howConvolve"></a></p>
<p>In the topology config file, any layer defined with a <em>convolve</em> parameter will operate as a convolution filter applied to the source layer. The syntax is of the form:</p>
<pre><code> layer2 size 64x64 from input convolve {{1,0,-1},{0,0,0},{-1,0,1}}</code></pre>
<p><strong>How do the color image pixels get converted to floating point for the input layer?</strong><a name="howRgb"></a></p>
<p>That's in the ReadBMP() function in neural2d-core.cpp. The default version of ReadBMP() converts each RGB pixel to a single floating point value in the range 0.0 to 1.0.</p>
<p>By default, the RGB color pixels are converted to monochrome and normalized to the range 0.0 to 1.0. That can be changed at runtime by setting the colorChannel member of the Net object to R, G, B, or BW prior to calling feedForward(). E.g., to use only the green color channel of the images, use:</p>
<pre><code>myNet.colorChannel = NNet::G;</code></pre>
<p>The color conversion can also be specified in the topology config file on the line that defines the input layer by setting the &quot;channel&quot; parameter to R, G, B, or BW, e.g.:</p>
<pre><code>input size 64x64 channel G</code></pre>
<p><strong>How can I use .jpg and .png images as inputs to the net?</strong><a name="howJpg"></a></p>
<p>Currently only .bmp images are supported. This is because the uncompressed BMP format is so simple that we can use simple, standard C/C++ to read the image data without any dependencies on third-party image libraries. To add an adapter for other image formats, follow the example of the ReadBMP() function and write a new adapter such as ReadJPG(), ReadPNG(), etc., using your favorite image library, then replace the call to ReadBMP() with your new function.</p>
<p><strong>Why does the net error rate stay high? Why doesn't my net learn?</strong><a name="howLearn"></a></p>
<p>Neural nets are finicky. Try different network topologies. Try starting with a larger eta values and reduce it incrementally. It could also be due to redundancy in the input data, or mislabeled target output values. Or you may need more training samples.</p>
<p><strong>What other parameters do I need to know about?</strong><a name="howParams"></a></p>
<p>Check out the <a href="https://github.com/davidrmiller/neural2d/wiki/ParameterList">list of parameters in the wiki</a>.</p>
<h2 id="licenses">Licenses<a name="Licenses"></a></h2>
<p>The neural2d program and its documentation are copyrighted and licensed under the terms of the MIT license.</p>
<p>The set of digits images in the images/digits/ subdirectory are released to the public domain.</p>
